<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Micro_speech 範例程式-喚醒詞偵測：訓練模型 | TensorFlow Lite for Microcontroller (TFLM)</title>
  <meta name="description" content="TensorFlow Lite for Micrcontroller (TFLM) 實驗, 基於 Rmarkdown / bookdown 做成" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Micro_speech 範例程式-喚醒詞偵測：訓練模型 | TensorFlow Lite for Microcontroller (TFLM)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="TensorFlow Lite for Micrcontroller (TFLM) 實驗, 基於 Rmarkdown / bookdown 做成" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Micro_speech 範例程式-喚醒詞偵測：訓練模型 | TensorFlow Lite for Microcontroller (TFLM)" />
  
  <meta name="twitter:description" content="TensorFlow Lite for Micrcontroller (TFLM) 實驗, 基於 Rmarkdown / bookdown 做成" />
  

<meta name="author" content="Marconi Jiang" />


<meta name="date" content="2021-04-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-micro-speech-inference.html"/>
<link rel="next" href="chap-magic-wand.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">TensorFlow Lite for Microcontroller</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 前言</a></li>
<li class="chapter" data-level="2" data-path="chap-intro.html"><a href="chap-intro.html"><i class="fa fa-check"></i><b>2</b> Introducing TFLM (TensorFlow Lite for Microcontroller)</a></li>
<li class="chapter" data-level="3" data-path="prerequisite-.html"><a href="prerequisite-.html"><i class="fa fa-check"></i><b>3</b> Prerequisite 準備工作</a>
<ul>
<li class="chapter" data-level="3.1" data-path="prerequisite-.html"><a href="prerequisite-.html#git"><i class="fa fa-check"></i><b>3.1</b> git 及 github 簡單操作</a></li>
<li class="chapter" data-level="3.2" data-path="prerequisite-.html"><a href="prerequisite-.html#make"><i class="fa fa-check"></i><b>3.2</b> 認識 make 及簡單操作 (mbed cli 的操作必備技能之一)</a></li>
<li class="chapter" data-level="3.3" data-path="prerequisite-.html"><a href="prerequisite-.html#vmware"><i class="fa fa-check"></i><b>3.3</b> 在 Windows 10 下安裝 VMware Workstation Player 及 Ubuntu 18.04</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="prerequisite-.html"><a href="prerequisite-.html#事先準備"><i class="fa fa-check"></i><b>3.3.1</b> 0. 事先準備</a></li>
<li class="chapter" data-level="3.3.2" data-path="prerequisite-.html"><a href="prerequisite-.html#下載-ubuntu-18.04-iso-image-檔案-電腦需要至少-20gb-以上硬碟空間-預估下載時間-7-分鐘"><i class="fa fa-check"></i><b>3.3.2</b> 1. 下載 Ubuntu 18.04 ISO image 檔案 （電腦需要至少 20GB 以上硬碟空間, 預估下載時間： 7 分鐘）</a></li>
<li class="chapter" data-level="3.3.3" data-path="prerequisite-.html"><a href="prerequisite-.html#下載及安裝-vmware-workstation-player-預估下載時間-1-分鐘-操作時間10-分鐘"><i class="fa fa-check"></i><b>3.3.3</b> 2. 下載及安裝 VMWare Workstation Player (預估下載時間： &lt; 1 分鐘 / 操作時間：10 分鐘)</a></li>
<li class="chapter" data-level="3.3.4" data-path="prerequisite-.html"><a href="prerequisite-.html#安裝套件之準備工作-以下步驟-3---7-約需時-30-分鐘"><i class="fa fa-check"></i><b>3.3.4</b> 3. 安裝套件之準備工作 (以下步驟 3 - 7 約需時 30 分鐘 )</a></li>
<li class="chapter" data-level="3.3.5" data-path="prerequisite-.html"><a href="prerequisite-.html#安裝-arm-mbed-os-command-line-編譯程式-mbed-cli"><i class="fa fa-check"></i><b>3.3.5</b> 4. 安裝 ARM mbed-os command line 編譯程式 mbed-cli</a></li>
<li class="chapter" data-level="3.3.6" data-path="prerequisite-.html"><a href="prerequisite-.html#安裝-arm-gcc-compiler-編譯器"><i class="fa fa-check"></i><b>3.3.6</b> 5. 安裝 ARM GCC compiler (編譯器)</a></li>
<li class="chapter" data-level="3.3.7" data-path="prerequisite-.html"><a href="prerequisite-.html#下載-tensorflow-lite-for-microcontroller-tflm"><i class="fa fa-check"></i><b>3.3.7</b> 6. 下載 TensorFlow Lite for Microcontroller (TFLM)</a></li>
<li class="chapter" data-level="3.3.8" data-path="prerequisite-.html"><a href="prerequisite-.html#下載-stm32-f-系列工具箱"><i class="fa fa-check"></i><b>3.3.8</b> 7. 下載 STM32-F 系列工具箱</a></li>
<li class="chapter" data-level="3.3.9" data-path="prerequisite-.html"><a href="prerequisite-.html#開始執行-tensorflow-lite-for-microcontroller-程式"><i class="fa fa-check"></i><b>3.3.9</b> 8. 開始執行 TensorFlow Lite for Microcontroller 程式</a></li>
<li class="chapter" data-level="3.3.10" data-path="prerequisite-.html"><a href="prerequisite-.html#參考文件"><i class="fa fa-check"></i><b>3.3.10</b> 參考文件</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="prerequisite-.html"><a href="prerequisite-.html#arduinoide"><i class="fa fa-check"></i><b>3.4</b> Arduino IDE 安裝 - 方法一: 從 Arduino libraries 安裝 TensorFlowLite</a></li>
<li class="chapter" data-level="3.5" data-path="prerequisite-.html"><a href="prerequisite-.html#arduino-ide-安裝---方法二-從-makefile-安裝-tensorflowlite"><i class="fa fa-check"></i><b>3.5</b> Arduino IDE 安裝 - 方法二: 從 Makefile 安裝 TensorFlowLite</a></li>
<li class="chapter" data-level="3.6" data-path="prerequisite-.html"><a href="prerequisite-.html#esp-idf"><i class="fa fa-check"></i><b>3.6</b> ESP32-CAM 安裝 esp-idf 開發環境</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="prerequisite-.html"><a href="prerequisite-.html#esp32-cam-硬體簡介"><i class="fa fa-check"></i><b>3.6.1</b> ESP32-CAM 硬體簡介</a></li>
<li class="chapter" data-level="3.6.2" data-path="prerequisite-.html"><a href="prerequisite-.html#esp-idf-安裝環境設定"><i class="fa fa-check"></i><b>3.6.2</b> esp-idf 安裝環境設定</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap-hello-world-training.html"><a href="chap-hello-world-training.html"><i class="fa fa-check"></i><b>4</b> Hello_world 範例程式 - 訓練</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chap-hello-world-training.html"><a href="chap-hello-world-training.html#在-google-colab-上建立及訓練-hello_world-的模型"><i class="fa fa-check"></i><b>4.1</b> 在 Google colab 上建立及訓練 hello_world 的模型</a></li>
<li class="chapter" data-level="4.2" data-path="chap-hello-world-training.html"><a href="chap-hello-world-training.html#colab-執行-training-程式前的準備工作"><i class="fa fa-check"></i><b>4.2</b> colab 執行 training 程式前的準備工作</a></li>
<li class="chapter" data-level="4.3" data-path="chap-hello-world-training.html"><a href="chap-hello-world-training.html#colab-執行-train-hello_world-model.ipynb-程式"><i class="fa fa-check"></i><b>4.3</b> colab 執行 train hello_world model.ipynb 程式</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="chap-hello-world-training.html"><a href="chap-hello-world-training.html#訓練過程中-學習如何修正及改善模型-並將模型轉換成-tflm-接受的格式"><i class="fa fa-check"></i><b>4.3.1</b> 訓練過程中, 學習如何修正及改善模型, 並將模型轉換成 TFLM 接受的格式</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html"><i class="fa fa-check"></i><b>5</b> Hello_world 範例程式 - 推論</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html#disco-f746ng-hello-world"><i class="fa fa-check"></i><b>5.1</b> 在 STM32 DISCO_F746NG 上實現 hello_world</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html#無痛執行在筆電上編譯程式-並下載至-stm32-disco_f746ng"><i class="fa fa-check"></i><b>5.1.1</b> (無痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG</a></li>
<li class="chapter" data-level="5.1.2" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html#微痛執行在筆電上編譯程式-並下載至-stm32-disco_f746ng"><i class="fa fa-check"></i><b>5.1.2</b> (微痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG</a></li>
<li class="chapter" data-level="5.1.3" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html#痛苦的-debug過程-disco_f746ng-執行-hello_world-當機"><i class="fa fa-check"></i><b>5.1.3</b> (痛苦的 debug過程) DISCO_F746NG 執行 hello_world 當機</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html#arduino-nano33-hello-world"><i class="fa fa-check"></i><b>5.2</b> 在 Arduino Nano 33 BLE 上實現 hello_world</a></li>
<li class="chapter" data-level="5.3" data-path="chap-hello-world-inference.html"><a href="chap-hello-world-inference.html#esp32-cam-hello-world"><i class="fa fa-check"></i><b>5.3</b> 在 ESP32-CAM 上實現 hello_world</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap-micro-speech-inference.html"><a href="chap-micro-speech-inference.html"><i class="fa fa-check"></i><b>6</b> Micro_speech 範例程式-喚醒詞偵測：建構 app</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chap-micro-speech-inference.html"><a href="chap-micro-speech-inference.html#disco-f746ng-micro-speech"><i class="fa fa-check"></i><b>6.1</b> 在 STM32 DISCO_F746NG 上實現 micro_speech</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="chap-micro-speech-inference.html"><a href="chap-micro-speech-inference.html#無痛執行在筆電上編譯程式-並下載至-stm32-disco_f746ng-1"><i class="fa fa-check"></i><b>6.1.1</b> (無痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG</a></li>
<li class="chapter" data-level="6.1.2" data-path="chap-micro-speech-inference.html"><a href="chap-micro-speech-inference.html#微痛執行在筆電上編譯程式-並下載至-stm32-disco_f746ng-1"><i class="fa fa-check"></i><b>6.1.2</b> (微痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="chap-micro-speech-inference.html"><a href="chap-micro-speech-inference.html#disco-nano33-micro-speech"><i class="fa fa-check"></i><b>6.2</b> 在 Arduino Nano 33 BLE 上實現 micro_speech</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html"><i class="fa fa-check"></i><b>7</b> Micro_speech 範例程式-喚醒詞偵測：訓練模型</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#在-google-colab-上建立及訓練-micro_speech-的模型-原始程式及設定"><i class="fa fa-check"></i><b>7.1</b> 在 Google colab 上建立及訓練 micro_speech 的模型 (原始程式及設定)</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#colab-執行-training-程式前的準備工作-1"><i class="fa fa-check"></i><b>7.1.1</b> colab 執行 training 程式前的準備工作</a></li>
<li class="chapter" data-level="7.1.2" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#colab-執行-train-micro_speech-model.ipynb-程式"><i class="fa fa-check"></i><b>7.1.2</b> colab 執行 train micro_speech model.ipynb 程式</a></li>
<li class="chapter" data-level="7.1.3" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#將模型上傳至開發板"><i class="fa fa-check"></i><b>7.1.3</b> 將模型上傳至開發板</a></li>
<li class="chapter" data-level="7.1.4" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#接續執行-make-及程式上傳"><i class="fa fa-check"></i><b>7.1.4</b> 接續執行 make 及程式上傳</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#colab-micro-speech-customization"><i class="fa fa-check"></i><b>7.2</b> 在 Google colab 上建立及訓練客製化 micro_speech 的模型</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#修改-colab-訓練程式"><i class="fa fa-check"></i><b>7.2.1</b> 修改 colab 訓練程式</a></li>
<li class="chapter" data-level="7.2.2" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#更換模型---將-colab-訓練結果的-g_model-內容複製貼上到-model.cc-1"><i class="fa fa-check"></i><b>7.2.2</b> 更換模型 - 將 colab 訓練結果的 g_model[ ] 內容複製貼上到 model.cc</a></li>
<li class="chapter" data-level="7.2.3" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#修改-micro_model_settings.cc"><i class="fa fa-check"></i><b>7.2.3</b> 修改 micro_model_settings.cc</a></li>
<li class="chapter" data-level="7.2.4" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#修改-command_responder.cc"><i class="fa fa-check"></i><b>7.2.4</b> 修改 command_responder.cc</a></li>
<li class="chapter" data-level="7.2.5" data-path="chap-micro-speech-training.html"><a href="chap-micro-speech-training.html#接續執行-make-及程式上傳-1"><i class="fa fa-check"></i><b>7.2.5</b> 接續執行 make 及程式上傳</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chap-magic-wand.html"><a href="chap-magic-wand.html"><i class="fa fa-check"></i><b>8</b> Magic_wand 範例程式</a></li>
<li class="chapter" data-level="9" data-path="chap-person-detection.html"><a href="chap-person-detection.html"><i class="fa fa-check"></i><b>9</b> Person_detection 範例程式</a></li>
<li class="chapter" data-level="" data-path="references-.html"><a href="references-.html"><i class="fa fa-check"></i>References 參考文獻</a></li>
<li class="appendix"><span><b>附錄</b></span></li>
<li class="chapter" data-level="A" data-path="appendixa.html"><a href="appendixa.html"><i class="fa fa-check"></i><b>A</b> Appendix A - 機器學習模型之加強及改善可能</a></li>
<li class="chapter" data-level="B" data-path="appendixb.html"><a href="appendixb.html"><i class="fa fa-check"></i><b>B</b> Appendix B - Hello_world 原始碼分析</a></li>
<li class="chapter" data-level="C" data-path="appendixc.html"><a href="appendixc.html"><i class="fa fa-check"></i><b>C</b> Appendix C - 音頻聲譜的說明與模型分析</a></li>
<li class="divider"></li>
<li><a href="https://github.com/marconi1964" target="blank">Marconi's github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">TensorFlow Lite for Microcontroller (TFLM)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap-micro-speech-training" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Micro_speech 範例程式-喚醒詞偵測：訓練模型</h1>
<p>本章節對應到 <a href="https://www.books.com.tw/products/0010865580">TinyML TensorFLow Lite 機器學習中文版</a> 的第八章, 在這一章裡, 也介紹了 TensorBoard 來監看訓練過程, 可以進一步了解可視化機器學習. 本章最後一小部分, 也再說明語音特徵生產的程序, 這部分, 我有機會再於 Appendix §<a href="appendixc.html#appendixc">C</a> 音頻聲譜的說明與模型分析說明.</p>
<p>類似 hello_world 的範例程式的模型訓練是於 Google colab 上執行, 此 micro_speech 範例也是在 colab 上執行另一個模型訓練程式, 我們先不做任何的修改, 於下一段的 <a href="chap-micro-speech-training.html#colab-micro-speech-customization">colab 訓練客製化</a>可以修改原始辨識 ‘yes’ 與 ‘no’ 的模型, 改為辨識其它喚醒詞.</p>
<div id="在-google-colab-上建立及訓練-micro_speech-的模型-原始程式及設定" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> 在 Google colab 上建立及訓練 micro_speech 的模型 (原始程式及設定)</h2>
<p>到 <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb">github 的 Train a Simple TensorFlow Lite for Microcontrollers model</a> 會同時看到 “在 Google colab 上執行” 及 “github 原始碼” 的圖示如下, 我們點選 “在 Google colab 上執行,” 就會在 browser 上新開一個畫面, 執行 colab 上的 training 程式.</p>
<p><a href="https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb"><img src="images/colab.png" alt="colabandgithub" style="height: 80px"></a>
<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb"><img src="images/github.png" alt="colabandgithub" style="height: 80px"></a></p>
<div id="colab-執行-training-程式前的準備工作-1" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> colab 執行 training 程式前的準備工作</h3>
<p>機器學習需要大量的運算, 尤其是浮點運算, 所以 NVidia 的 GPU 比 intel 的 CPU 更適合做機器學習的訓練工作, 可以縮短大量的訓練時間. Google 的 colab 提供了 3 種 runtime type 的選擇, 到選單 ‘Runtime’ 下的 “Change runtime type” 選擇 GPU. (如果選擇 None, 就會使用 CPU, 選擇 TPU, 會使用 Google 特殊設計的機器學習加速晶片, 截至目前為止, GPU 還是機器學習訓練速度最快的選項. 只是, 本次訓練的模型不大, 不管選擇哪一種, 時間都差異不大)</p>
</div>
<div id="colab-執行-train-micro_speech-model.ipynb-程式" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> colab 執行 train micro_speech model.ipynb 程式</h3>
<p>到選單 “Runtime” 選擇 “Run all,” 整個執行過程所需時間比 hello_world 的訓練長出許多, 我曾經有跑過 4 個小時以上 (可能是我同時在 colab 有跑其它應用有關, 同學們可以試試看不同的 runtime type 所需的時間各是多少), 原始程式也提供一個縮短訓練時間的方式, 把下面最底下 2 行的指令 # 拿掉 (!curl 跟 !tar 開頭那 2 行) , 直接下載已經訓練好的模型, 我在這樣條件下執行的時間約為 3.5 個小時.</p>
<pre><code>Skipping the training

If you don&#39;t want to spend an hour or two training the model from scratch, you can download pretrained checkpoints by uncommenting the lines below (removing the &#39;#&#39;s at the start of each line) and running them.</code></pre>
<pre><code>#!curl -O &quot;https://storage.googleapis.com/download.tensorflow.org/models/tflite/speech_micro_train_2020_05_10.tgz&quot;
#!tar xzf speech_micro_train_2020_05_10.tgz
</code></pre>
</div>
<div id="將模型上傳至開發板" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> 將模型上傳至開發板</h3>
<p>類似 hello_world 的作法, 將 colab 訓練結果複製貼上到開發板的 app, 我們回到開發環境, 需要注意 3 個地方</p>
<ul>
<li><a href="chap-micro-speech-training.html#micro-speech-copy-gmodel">更換模型 - 複製貼上到 model.cc</a><br />
</li>
<li><a href="chap-micro-speech-training.html#micro-speech-model-settings">確認 micro_model_settings.cc</a><br />
</li>
<li><a href="chap-micro-speech-training.html#micro-speech-command-responder">確認 command_responder.cc</a></li>
</ul>
<p><a id="micro-speech-copy-gmodel"></a></p>
<div id="更換模型---將-colab-訓練結果的-g_model-內容複製貼上到-model.cc" class="section level4" number="7.1.3.1">
<h4><span class="header-section-number">7.1.3.1</span> 更換模型 - 將 colab 訓練結果的 g_model[ ] 內容複製貼上到 model.cc</h4>
<p>colab 訓練最後一行的 g_model[ ] 的內容 (書上寫的 g_tiny_conv_micro_features_model_data[ ] 資料太舊, 已經更新為 g_model[ ]), 複製貼上到 , tensorflow/lite/micro/examples/micro_speech/micro_features/model.cc 內容的 g_model[ ]. 並確認 g_model_len = 18712 的數字部份與 colab 的 g_model_len 一致, 如有不同, 採用 colab 的數字.</p>
<pre><code>!cat {MODEL_TFLITE_MICRO}

const unsigned char g_model[] DATA_ALIGN_ATTRIBUTE = {
  0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,
  0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00,
  0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x12, 0x00, 0x00, 0x00,
  0x03, 0x00, 0x00, 0x00, 0x94, 0x48, 0x00, 0x00, 0x34, 0x42, 0x00, 0x00,
  0x1c, 0x42, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,
  ......
  0x06, 0x00, 0x00, 0x00, 0x00, 0x16, 0x0a, 0x00, 0x0e, 0x00, 0x07, 0x00,
  0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,
  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x0c, 0x00, 0x07, 0x00,
  0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04,
  0x03, 0x00, 0x00, 0x00};
const int g_model_len = 18712;
</code></pre>
<p><a id="micro-speech-model-settings"></a></p>
</div>
<div id="確認-micro_model_settings.cc" class="section level4" number="7.1.3.2">
<h4><span class="header-section-number">7.1.3.2</span> 確認 micro_model_settings.cc</h4>
<p>打開 examples/micro_speech/micro_features/micro_model_settings.cc, 這個檔案有關類別標籤陣列, 確定跟 colab 裡面的是一致的.</p>
<pre><code>const char* kCategoryLabels[kCategoryCount] = {
    &quot;silence&quot;,
    &quot;unknown&quot;,
    &quot;yes&quot;,
    &quot;no&quot;,
};
</code></pre>
<p><a id="micro-speech-command-responder"></a></p>
</div>
<div id="確認-command-responder.cc---以-disco_f746ng-為例" class="section level4" number="7.1.3.3">
<h4><span class="header-section-number">7.1.3.3</span> 確認 command-responder.cc - 以 DISCO_F746NG 為例</h4>
<p>DISCO_F746NG 指令回應器檔案位於 examples/micro_speech/disco_f746ng/command_responder.cc, 它會根據聽到的指令來顯示不同的單字, 在檔案裡面可以找到這個 if 陳述式:</p>
<pre><code>    if (*found_command == &#39;y&#39;) {
      lcd.Clear(0xFF0F9D58);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard yes!&quot;, CENTER_MODE);
    } else if (*found_command == &#39;n&#39;) {
      lcd.Clear(0xFFDB4437);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard no&quot;, CENTER_MODE);
    } else if (*found_command == &#39;u&#39;) {
      lcd.Clear(0xFFF4B400);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard unknown&quot;, CENTER_MODE);
    } else {
      lcd.Clear(0xFF4285F4);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard silence&quot;, CENTER_MODE);
    }</code></pre>
</div>
</div>
<div id="接續執行-make-及程式上傳" class="section level3" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> 接續執行 make 及程式上傳</h3>
<p><strong>接下去再回頭執行上一章介紹的推論部份的動作 §<a href="chap-micro-speech-inference.html#micro-speech-deployment">6.1.2.2</a> 修改 disco_f746ng 目錄繼續執行.</strong></p>
<p><a id="colab-micro-speech-customization"></a></p>
</div>
</div>
<div id="colab-micro-speech-customization" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> 在 Google colab 上建立及訓練客製化 micro_speech 的模型</h2>
<p>我們接下來進行的客製化的過程, 可以讓你選擇的開發板, 不僅是辨識此範例中的 ‘yes’ 與 ‘no,’ 而是有其它選擇, 甚至超過 2 個以上的單字當作喚醒詞辨識. 因為範例中的模型設計, 可以選取的單字有下列, 我們會選用 ‘on’ 與 ‘off’ 當作此次的範例.</p>
<ul>
<li>常見指令: yes, no, up, down, left, right, on, off, stop, go backward, foward, follow, learn</li>
<li>0 - 9 數字: zero, one, two, three, four, five, six, seven, eight, nine</li>
<li>隨機單字: bed, bird, cat, dog, happy, house, Marvin, Sheila, tree, wow</li>
</ul>
<p>需要修改的有 4 個部份, 1 個在 colab 訓練程式, 3 個在開發板開發環境的程式內容</p>
<ul>
<li>修改 colab 訓練程式</li>
<li>更換模型</li>
<li>修改 micro_model_settings.cc<br />
</li>
<li>修改 command_responder.cc (⚠️ 注意: 如果是選用其它開發板, 如 DISCO_F746NG 時, Makefile 會選用其它目錄下的 /micro_speech/disco_f746ng/command_responder.cc, 這時候需要修改的檔案就是 disco_f746ng 目錄下的)</li>
</ul>
<div id="修改-colab-訓練程式" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> 修改 colab 訓練程式</h3>
<p>到 <a href="https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb">Google colab 的 train_micro_speech_model.ipynb</a> 下尋找 WANTED_WORDS, 可以看到下面這行</p>
<pre><code>WANTED_WORDS = &quot;yes,no&quot;</code></pre>
<p>我們接下來的練習用 ‘on,’ ‘off’ 來取代</p>
<pre><code>WANTED_WORDS = &quot;on, off&quot;</code></pre>
<p>到選單 “Runtime” 選擇 “Run all”</p>
</div>
<div id="更換模型---將-colab-訓練結果的-g_model-內容複製貼上到-model.cc-1" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> 更換模型 - 將 colab 訓練結果的 g_model[ ] 內容複製貼上到 model.cc</h3>
<p>等 colab 訓練完成後, 將最後一行的 g_model[ ] 的內容 (書上寫的 g_tiny_conv_micro_features_model_data[ ] 資料太舊, 已經更新為 g_model[ ]), 複製貼上到 , tensorflow/lite/micro/examples/micro_speech/micro_features/model.cc 內容的 g_model[ ]. 並確認 g_model_len = 18712 的數字部份與 colab 的 g_model_len 一致, 如有不同, 採用 colab 的數字.</p>
<pre><code>!cat {MODEL_TFLITE_MICRO}

const unsigned char g_model[] DATA_ALIGN_ATTRIBUTE = {
  0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,
  0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00,
  0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x12, 0x00, 0x00, 0x00,
  0x03, 0x00, 0x00, 0x00, 0x94, 0x48, 0x00, 0x00, 0x34, 0x42, 0x00, 0x00,
  0x1c, 0x42, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,
  ......
  0x06, 0x00, 0x00, 0x00, 0x00, 0x16, 0x0a, 0x00, 0x0e, 0x00, 0x07, 0x00,
  0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,
  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x0c, 0x00, 0x07, 0x00,
  0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04,
  0x03, 0x00, 0x00, 0x00};
const int g_model_len = 18712;
</code></pre>
</div>
<div id="修改-micro_model_settings.cc" class="section level3" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> 修改 micro_model_settings.cc</h3>
<p>打開 tensorflow/lite/micro/examples/micro_speech/micro_features/micro_model_settings.cc, 這個檔案有關類別標籤陣列：</p>
<pre><code>const char* kCategoryLabels[kCategoryCount] = {
    &quot;silence&quot;,
    &quot;unknown&quot;,
    &quot;yes&quot;,
    &quot;no&quot;,
};
</code></pre>
<p>我們為新模型進行調整, 將 ‘yes’ 與 ‘no’ 換成 ‘on’ 與 ‘off,’ 我們讓標籤的順序與模型輸出張量 (tensor) 的元素順序一樣, 讓它們的順序與訓練腳本裡面的相同非常重要. (如果用來訓練模型的標籤超過 2 個, 只要將它們都加入這個串列即可)</p>
<pre><code>const char* kCategoryLabels[kCategoryCount] = {
    &quot;silence&quot;,
    &quot;unknown&quot;,
    &quot;on&quot;,
    &quot;off&quot;,
};
</code></pre>
</div>
<div id="修改-command_responder.cc" class="section level3" number="7.2.4">
<h3><span class="header-section-number">7.2.4</span> 修改 command_responder.cc</h3>
<p>最後一個步驟是修改使用這些標籤的輸出程式碼, 我們以 STM32 DISCO_F746NG 為例. STM32 DISCO_F746NG 指令回應器位於 examples/micro_speech/disco_f746ng/command_responder.cc, 它會根據聽到的指令來顯示不同的單字, 在 command_responder.cc 裡面找到以下這個 if 陳述式:</p>
<pre><code>    if (*found_command == &#39;y&#39;) {
      lcd.Clear(0xFF0F9D58);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard yes!&quot;, CENTER_MODE);
    } else if (*found_command == &#39;n&#39;) {
      lcd.Clear(0xFFDB4437);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard no&quot;, CENTER_MODE);
    } else if (*found_command == &#39;u&#39;) {
      lcd.Clear(0xFFF4B400);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard unknown&quot;, CENTER_MODE);
    } else {
      lcd.Clear(0xFF4285F4);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard silence&quot;, CENTER_MODE);
    }</code></pre>
<p>將它改成回應 ‘on’ 與 ‘off’ 不算太難, 只是之前只要判斷第一個字母的差異 (*found_command 來區分 yes 第一個字母的 ‘y’ 與 no 的 ‘n’), 現在必須用 2 個字母來區別 (found_command[0] 與 found_command[1] 來區分 on 的 ‘on’ 與 off 的 ‘of’)</p>
<pre><code>    if (found_command[0] == &#39;o&#39; &amp;&amp; found_command[1] == &#39;n&#39;) {
      lcd.Clear(0xFF0F9D58);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard on!&quot;, CENTER_MODE);
    } else if (found_command[0] == &#39;o&#39; &amp;&amp; found_command[1] == &#39;f&#39;) {
      lcd.Clear(0xFFDB4437);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard off&quot;, CENTER_MODE);
    } else if (*found_command == &#39;u&#39;) {
      lcd.Clear(0xFFF4B400);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard unknown&quot;, CENTER_MODE);
    } else {
      lcd.Clear(0xFF4285F4);
      lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard silence&quot;, CENTER_MODE);
    }</code></pre>
</div>
<div id="接續執行-make-及程式上傳-1" class="section level3" number="7.2.5">
<h3><span class="header-section-number">7.2.5</span> 接續執行 make 及程式上傳</h3>
<p><strong>接下去再回頭執行上一章介紹的推論部份的動作 §<a href="chap-micro-speech-inference.html#micro-speech-deployment">6.1.2.2</a> 修改 disco_f746ng 目錄繼續執行.</strong></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-micro-speech-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-magic-wand.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TensorFlowLite4Microcontrollers_by_marconi1964.pdf", "TensorFlowLite4Microcontrollers_by_marconi1964.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
