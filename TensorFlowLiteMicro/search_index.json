[["index.html", "TensorFlow Lite for Microcontroller (TFLM) Chapter 1 前言", " TensorFlow Lite for Microcontroller (TFLM) marconi1964@yahoo.com or marconi.jiang@gmail.com 2021-04-07 Chapter 1 前言 自從 2020 年參加了台灣人工智慧學校的第一屆 Edge AI 技術專班後, 對於 edge AI 比較有點概念, 重讀 TinyML：TensorFlow Lite機器學習 一書, 於 2021 春節期間比較有空時, 找出手上的 STM32 NUCLEO_F103RB 板子, 確認程式的可行性, 分享在 FB 的 Edge AI Taiwan邊緣智能交流區, 接著就開始了 TensorFlow Lite for Microcontroller 更深入的探討, 同時, 也開啟了對 TensorFlow open source 的小小貢獻. 附註 : 本書的 pdf 版本下載設定有問題, 無法顯示中文, 需要修改 bookdown 設定吧, 待研究. "],["chap-intro.html", "Chapter 2 Introducing TFLM (TensorFlow Lite for Microcontroller)", " Chapter 2 Introducing TFLM (TensorFlow Lite for Microcontroller) Google 推出 TensorFlow 框架, 可以在 CPU/GPU/TPU 上執行 training 的任務, 考慮手機上的侷限的運算能力不如 PC, 接著推出 Tensorflow Lite 的機器學習框架於手機, 至於 IoT 裝置上用的是 ARM M 系列及其它 embedded MCU (microcontrollers) 的算力以及侷限的 ROM/RAM 空間, 也針對這類型的開發板陸續推出支援機器學習 inference 的 TensorFlow Lite for Microcontrollers (TFLM) 框架, 也出書推廣 TinyML：TensorFlow Lite 機器學習. 截至本文上架（2021-04-07）為止, TFLM 支援的硬體已經有下列的開發板 (書中只有介紹前三種): Arduino Nano 33 BLE Sense SparkFun Edge STM32F746 Discovery kit Adafruit EdgeBadge Adafruit TensorFlow Lite for Microcontrollers Kit Adafruit Circuit Playground Bluefruit Espressif ESP32-DevKitC Espressif ESP-EYE Wio Terminal: ATSAMD51 Himax WE-I Plus EVB Endpoint AI Development Board Synopsys DesignWare ARC EM Software Development Platform 而介紹的範例則有 Hello World - 示範 TensorFlow Lite for Microcontrollers 的基本功能, 用機器學習的 inference 來推算出 sine 的值 Tutorial using any supported device Micro speech - 從麥克風接收語音, 偵測 wake words: “yes,” “no,” “silence” 及 “unkown” Tutorial using SparkFun Edge Magic wand - 讀取 accelerometer 資料來判斷並區分 3 種不同手勢 Tutorial using Arduino Nano 33 BLE Sense Person detection - 讀取 camera 的影像資料來偵測是否有人出現在精通前 而我在本文上架時, 已經實驗過的板子及範例有, * Hello World : STM32 NUCLEO-F03RB, DISCO-F746NG, Arduino Nano 33 BLE Sense, ESP32-CAM (2021/4/5 新增). (期待中: 標的物 Sipeed Maix Amigo on RISC-V RV64GC) * Micro speech : DISCO-F746NG, Arduino Nano 33 BLE Sense * Magic wand : Arduino Nano 33 BLE Sense * Person detection : ESP32-CAM (2021/4/6 新增) （期待中: 標的物 Arduino Nano 33 BLE Sense） 因為 TensorFlow Lite Micro 的核心程式及 Make 環境的開發持續進行中, 程式的更新過程會造成部分來不及更新的內容及操作產生錯誤, 尤其是 STM32 相關的設定參數, 著實花了一些時間, 並且發 PR 到 TFLM github 更新, ESP32-CAM 也需要注意些小地方. 再者, 從實驗的結果而言, 辨識的效果還有很大的改善空間, 這就當作下一個探討的題目吧. "],["prerequisite-.html", "Chapter 3 Prerequisite 準備工作 3.1 git 及 github 簡單操作 3.2 認識 make 及簡單操作 (mbed cli 的操作必備技能之一) 3.3 在 Windows 10 下安裝 VMware Workstation Player 及 Ubuntu 18.04 3.4 Arduino IDE 安裝 - 方法一: 從 Arduino libraries 安裝 TensorFlowLite 3.5 Arduino IDE 安裝 - 方法二: 從 Makefile 安裝 TensorFlowLite 3.6 ESP32-CAM 安裝 esp-idf 開發環境", " Chapter 3 Prerequisite 準備工作 本章介紹的準備工作, 以不同的開發板區分成幾段: §3.1, §3.2 及 §3.3 是準備給 STM32 DISCO F746NG (或其它 STM 及使用 ARM MCU 系列) demo board 如果是 Arduino Nano 33 BLE Sense, 則直接到 §3.4 準備 Arduino IDE, 相對而言, 簡單許多. (2021/4/5 新增: 用 Makefile 來產生 Arduino 的 examples 程式) §3.6 說明 ESP32 的 idf 開發環境安裝 3.1 git 及 github 簡單操作 $ git clone https://github.com/marconi1964/tensorflow.git $ cd tensorflow $ git pull # 每次修改前, 下載 github 最新的內容 # 新增/修改檔案後 $ git add * $ git commit -m “修改內容的註釋” $ git push origin master # 新的 github 已經改成 main # 或是簡單點 # git push git stash 的作法 # 有時候, 忘了 git pull 就修改 local 檔案時, 跟 github remote 上的檔案有衝突時該怎麼辦? # 不麻煩, git stash 可以解決這個問題 $ git stash # 將修改過的內容暫存起來 $ git pull $ git pop # 或 git apply, 差別在於 git pop 後, 暫存內容就消失, 而 git apply 的暫存內容依舊存在 # 這時候, 會列出內容有衝突的檔案名稱, 可以直接修改該檔案(同時列出有衝突的內容) # 修改後, 記得 push 去 更新 remote 內容 $ git push # 更新到 github remote 內容 $ git stash drop # 暫存內容已無必要, 可以扔了 3.2 認識 make 及簡單操作 (mbed cli 的操作必備技能之一) 見參考文件 跟 Seisman 一起写Makefile 3.3 在 Windows 10 下安裝 VMware Workstation Player 及 Ubuntu 18.04 本篇文章(原先我撰寫載於github/tensorflow/lite/micro/examples/README.md)說明如何在 Windows 10 上安裝虛擬機器, 執行 Linux - Ubuntu 系統, 以便編譯 TensorFlow Lite Micro 在 STM32 DISCOVERY_F476NG 板子上執行的測試程式 3.3.1 0. 事先準備 0.1 需要一個 email 位址作為網站下載軟體之註冊用, 0.2 需要在 github.com 上面開個帳號, 對以後的軟體開發會有幫助 3.3.2 1. 下載 Ubuntu 18.04 ISO image 檔案 （電腦需要至少 20GB 以上硬碟空間, 預估下載時間： 7 分鐘） https://releases.ubuntu.com/18.04/ 選擇 ubuntu-18.04.5-desktop-amd64.iso 下載, 記住儲存目錄 3.3.3 2. 下載及安裝 VMWare Workstation Player (預估下載時間： &lt; 1 分鐘 / 操作時間：10 分鐘) 2.1 下載 VMWare Workstation Player 安裝程式檔案 https://www.vmware.com/products/workstation-player/workstation-player-evaluation.html 2.2 執行 VMWare Workstation Player 安裝程式 安裝完成後, 執行 VMware Workstation Player 2.3 Create a new virtual machine. 點選 ‘Installer disc image file (iso),’ 到儲存 ubuntu-18.04.5-desktop-amd64.iso 的目錄後, 開始安裝 *** 以上 2 個動作在上課前完成 *** 3.3.4 3. 安裝套件之準備工作 (以下步驟 3 - 7 約需時 30 分鐘 ) 進入 Ubuntu OS 後, 打開 terminal 檔案 要記得 Ubuntu 的密碼, 執行 sudo 後需要輸入 $ sudo apt update $ sudo apt install -y git curl mercurial python2.7 python-pip python3-pip build-essential screen # Python2 跟 Python3 都會用的到, 用不同的指令來區分 : python 會指向 Python2; python3 會指向 Python3 (不要問我問甚麼會同時用到 2 個不同版本, 不同的開發團隊, 習慣的作法不同) 3.3.5 4. 安裝 ARM mbed-os command line 編譯程式 mbed-cli 參考文章 mbed-cli installation $ pip install mbed-cli 3.3.5.1 4.1 設定 mbed 目錄路徑(path) $ sudo find / -name mbed $ vi ~/.bashrc # 在 .bashrc 檔案的最後一行 按鍵指令 &#39;a&#39; (append) 加上以下內容, 記得, 不要加上 /mbed export PATH=$PATH:/path/to/mbed/you/find # 我自己的例子是 export PATH=$PATH:/home/ubuntu/.local/bin # 結束後, 按鍵 &#39;:wq!&#39; 來儲存 $ source ~/.bashrc $ mbed --version # 測試是否正確執行 3.3.6 5. 安裝 ARM GCC compiler (編譯器) 參考文件 GNU Arm Embedded Toolchain # 第一步: 在 Ubuntu OS 內, 打開 terminal 並輸入 $ sudo add-apt-repository ppa:team-gcc-arm-embedded/ppa # 按 &#39;enter&#39; 繼續 # 第一步: 更新 apt $ sudo apt update # 第三步: 安裝 gcc-arm toolchain $ sudo apt install -y gcc-arm-embedded # 設定 mbed 目錄路徑(path) $ vi ~/.bashrc # 在 .bashrc 檔案的最後一行 按鍵指令 &#39;a&#39; (append) 加上以下內容 export GCC_ARM_PATH=/usr/bin/arm-none-eabi-gcc # 結束後, 按鍵 &#39;:wq!&#39; 來儲存 $ source ~/.bashrc # 安裝完成, 測試是否正確執行 $ gcc --version # 第四步: 安裝 Arm Compiler 5 到 64-bit Linux 系統時, 需要安裝 i386 architecture package $ sudo dpkg --add-architecture i386 $ sudo apt update $ sudo apt install -y libc6:i386 libncurses5:i386 libstdc++6:i386 3.3.7 6. 下載 TensorFlow Lite for Microcontroller (TFLM) # clone from tensorflow github $ git clone -b example --depth 1 https://github.com/marconi1964/tensorflow.git 3.3.8 7. 下載 STM32-F 系列工具箱 7.1 更新 STM32-F 板子的 ST-LINK firmware 到最新版 https://my.st.com/content/my_st_com/en/products/development-tools/software-development-tools/stm32-software-development-tools/stm32-programmers/stsw-link007.html Linux Ubuntu 版本 $ cd stsw-link007/AllPlatforms/StlinkRulesFilesForLinux $ sudo apt update $ sudo dpkg -i st-stlink-udev-rules-1.0.2-2-linux-all.deb 7.2 下載 CoolTerm 程式 https://freeware.the-meiers.org/ 也可以用步驟 3 已經安裝好的 cli 指令 screen, screen 是比較炫技的方法, CoolTerm 對不熟 Linux 環境的人比較 friendly 3.3.9 8. 開始執行 TensorFlow Lite for Microcontroller 程式 見下一章範例 - Hello_world 3.3.10 參考文件 關於 Make 及 Makefile &gt; - 取消 TAGS 程式不受影響 &gt; - STM32F 選用 OPTIMIZED_KERNEL_DIR=cmsis_nn 來做最佳化 英文參考文章 &gt; - mbed-cli v6.7 installation &gt; - mbed-cli v5.15 manual installation &gt; - Build Arm Cortex-M voice assistant with Google TensorFlow Lite &gt; - CMSIS - Cortex Microcontroller Software Interface Standard &gt; - STM32F10x Standard Peripherals Library Peripheral’s Drivers Description &gt; - what means about “-DSTM32F10X_MD -DUSE_STDPERIPH_DRIVER” as the flags of arm-none-eabi-gcc? 3.4 Arduino IDE 安裝 - 方法一: 從 Arduino libraries 安裝 TensorFlowLite 坊間許多的 Arduino 書/網站都有詳細的 Arduino IDE 安裝介紹, 例如 台灣智能感測科技 Arduino IDE 安裝, 就不在此佔用篇幅, Arduino IDE 安裝完成後, 需要在 Arduino IDE 上安裝 Nano 33 BLE 硬體跟 TensorFlow Lite 的範例程式, 簡單說明如下: 將 Arduino Nano 33 BLE 加入 Boards 支援: 到 Arduino menu 的 Tools - Board - Boards Manager 輸入 Nano 33 BLE, 找到後選擇最新版本安裝 ‘Install’ 到 Arduino menu 的 Tools - Manage Libraries, 輸入 TensorFlowLite 後選擇最新版本後安裝 ‘Install’ 到 Arduino menu 的 File - Examples - Arduino_TensorFlowLite 下會有 4 個範例 hello_world magic_wand micro_speech person_detection 選擇我們想要的範例 hello_world 執行即可. 偶爾, 在燒錄過程, 或是程式問題, 可能造成筆電無法偵測到 Arduino Nano 33, 找不到 COM port, 這時候, 可以參考 Arduino driver 問題 的 #7, 快速按 2 下 Arduino Nano 33 上面的 RESET 按鈕, 可以讓 Nano 33 回到燒錄模式, 就可以看到 Arduino Nano 33, 找到 COM port. 也許, 程式燒錄後, COM port 位址會變, (像我就遇到燒錄前的 COM 5, 到燒錄後的 COM 6), 這時候, 需要去 Arduino IDE 的 Tool - Port 選取對應到的 COM port. 3.5 Arduino IDE 安裝 - 方法二: 從 Makefile 安裝 TensorFlowLite 參照 TinyML：TensorFlow Lite機器學習 附錄 A 使用及產生 Arduino Library Zip. 採取類似 DISCO_F746NG 使用 Makefile 的作法產生 Arduino IDE 所需要的 library zip 檔案 tensorflow_lite.zip $ git clone --depth 1 https://github.com/tensorflow/tensorflow.git $ cd tensorflow # 執行 test_arduino.sh 來產生 .zip 檔 $ tensorflow/lite/micro/ci_build/test-arduino.sh # 可以在以下目錄找到 tensorflow_lite.zip $ ls tensorflow/lite/micro/tools/make/gen/arduino_x86_64_default/prj/tensorflow_lite.zip 記得剛才產生的 tensorflow_lite.zip 的目錄位置, 類似方法一的作法, 但是要修改步驟 2 1. 將 Arduino Nano 33 BLE 加入 Boards 支援: 到 Arduino menu 的 Tools - Board - Boards Manager 輸入 Nano 33 BLE, 找到後選擇最新版本安裝 ‘Install’ 2. 到 Arduino menu 的 Tools - Manage Libraries, 輸入 TensorFlowLite 後選擇最新版本後安裝 ‘Install’ 2. 到 Arduino menu 的 Sketch - Include Library - Add .ZIP Library, 選取剛才產生的 tensorflow_lite.zip 3. 到 Arduino menu 的 File - Examples - Arduino_TensorFlowLite 下會有 4 個範例 hello_world magic_wand micro_speech person_detection 選擇我們想要的範例 hello_world 執行即可. 3.6 ESP32-CAM 安裝 esp-idf 開發環境 3.6.1 ESP32-CAM 硬體簡介 ESP32-CAM 可以使用 Arduino IDE, 也可以使用 ESP32 官方的開發環境 esp-idf. 以下介紹 esp-idf 開發環境的設定為主: 本文使用的 ESP32-CAM 使用了 2 個硬體版本, * 需要外接 USB-serial 轉板 : 燒錄 ESP32-CAM 程式式, 需要將 GPIO 0 接到 GND, 詳見 ESP32-CAM Randomnerd-tutorials * 自帶 CH340 的 ESP32-CAM : 這種整合型的硬體穩定性較佳. 燒錄時, 切換下載模式步驟 : 按住Flash, 再按RST, 放開RST, 放開Flash 這 2 個硬體版本的軟體設定都是選擇 AI thinker ESP32-CAM (不管是用 Arduino IDE 或是 esp-idf) 3.6.2 esp-idf 安裝環境設定 基本上, 照著 Espressif ESP-IDF Programming Guide 上的詳細說明, 大致上不會遇到問題. 我用的是 command line 的 tool chain, Toolchain to compile code for ESP32 Build tools - CMake and Ninja to build a full Application for ESP32 ESP-IDF that essentially contains API (software libraries and source code) for ESP32 and scripts to operate the Toolchain 而不是 Eclipse 或 VS Code 的 IDE Eclipse Plugin (installation link) VS Code Extension (onboarding) 照著網頁上的 10 個步驟逐步完成, 算是簡單 Step 1. Install prerequisites for Windows, Linux, or macOS Step 2. Get ESP-IDF Step 3. Set up the tools Step 4. Set up the environment variables 可以先執行範例程式, 確定沒有問題後, 再進行 TensorFlow Lite Micro 的範例, 才不會糾結在從何處 debug 著手的問題 Step 5. Start a Project Step 6. Connect Your Device Step 7. Configure (注意 1) Step 8. Build the Project Step 9. Flash onto the Device Step 10. Monitor (注意 2, 3, 4) 注意 1 : Step 7 的 config 無須特別設定, 看看後就可以 (Q)uit 我曾經卡在 step 9, VMware 下的 Ubuntu 18.04 讓我無法連接上 USB Serial port, 看得到, 但讀寫有問題,Google 了好幾回, 能找到的 Stackoverflow 最佳解 還是無法解決已經將 user 設定成 dialout 群組卻還無法讀寫 USB serial port 的問題, 只能用暴力的 chmod 作法. $ ls -l /dev/ttyUSB* crw-rw---- 1 root dialout 188,0 Apr 5 16:41 /dev/ttyUSB0 $ sudo chmod 666 /dev/ttyUSB0 $ ls -l /dev/ttyUSB* crw-rw-rw- 1 root dialout 188,0 Apr 5 16:41 /dev/ttyUSB0 注意 2 : Step 10 的 monitor 可以跟 step 9 的指令結合如下: $ idf.py -p PORT flash monitor # 這裡的 PORT 用 /dev/ttyUSB0 取代 注意 3 : 記得, 燒錄完成後, 雖然軟體會自動下個 soft reset, 可是 ESP32-CAM 都沒有動作, 還是需要按板子上的 RST 鍵才能執行新下載的程式. 注意 4 : 執行 monitor 程式時, 如果要離開, 需要按 ‘Ctrl’ + ‘]’ 的組合鍵. "],["chap-hello-world-training.html", "Chapter 4 Hello_world 範例程式 - 訓練 4.1 在 Google colab 上建立及訓練 hello_world 的模型 4.2 colab 執行 training 程式前的準備工作 4.3 colab 執行 train hello_world model.ipynb 程式", " Chapter 4 Hello_world 範例程式 - 訓練 本章節對應到 TinyML TensorFLow Lite 機器學習中文版 的第四章 Hello world 示範程式跟一般的 AI 機器學習/深度學習的應用一樣, 分成“訓練 (training)” 跟 “推論 (inference)” 兩段, 參考 AI 大神 NVidia 關於訓練與推論的文章(英文版) . 簡單而言: 訓練就是‘學習’; 推論就是‘考試’ ’訓練’需要大量的電腦資源 (CPU/GPU/NPU/memory) 、資料(data) 以及長時間的訓練, 就跟我們人類學習需要大量閱讀與長期的記憶, 而考試(推論)則需要我們的馬上反應; ’推論’是基於訓練出來的模型(如同我們大腦的記憶), 來推論出新資料的可能答案。因為訓練需要大量電腦資源, 我們無法使用開發板有限的 MCU 能力來做訓練, 而是需要電腦 (PC, Mac 甚至更快速的雲端伺服器, 如 google 的 colab) 來做訓練 (本章 §4 的內容), 再將訓練出來的模型轉換成開發板可以接受的檔案格式, 傳到開發板上來做推論,也就是下一章 §5 的內容. 4.1 在 Google colab 上建立及訓練 hello_world 的模型 到 github 的 Train a Simple TensorFlow Lite for Microcontrollers model 會同時看到 “在 Google colab 上執行” 及 “github 原始碼” 的圖示如下, 我們點選 “在 Google colab 上執行,” 就會在 browser 上新開一個畫面, 執行 colab 上的 training 程式. 4.2 colab 執行 training 程式前的準備工作 機器學習需要大量的運算, 尤其是浮點運算, 所以 NVidia 的 GPU 比 intel 的 CPU 更適合做機器學習的訓練工作, 可以縮短大量的訓練時間. Google 的 colab 提供了 3 種 runtime type 的選擇, 到選單 ‘Runtime’ 下的 “Change runtime type” 選擇 GPU. (如果選擇 None, 就會使用 CPU, 選擇 TPU, 會使用 Google 特殊設計的機器學習加速晶片, 截至目前為止, GPU 還是機器學習訓練速度最快的選項. 只是, 本次訓練的模型不大, 不管選擇哪一種, 時間都差異不大) 4.3 colab 執行 train hello_world model.ipynb 程式 到選單 “Runtime” 選擇 “Run all,” 整個執行過程需時 5 分鐘之內. (同學們可以試試看不同的 runtime type 所需的時間各是多少) 4.3.1 訓練過程中, 學習如何修正及改善模型, 並將模型轉換成 TFLM 接受的格式 這訓練模型 train hello worldmode.ipynb 令我佩服的是, 利用實例來說明機器學習模式設計可能的問題, 模型太小只能有線性的表現, 而且用圖形來顯示此結果, 進一步擴充模型(增加一層神經網路)後得到更佳結果, 值得讀者細細研讀本書TinyML TensorFLow Lite 機器學習中文版的第 4 章, 列於 § Appendix A 當作進一步研究的主題. 最終訓練結果會顯示在最後一行, 帶出 2 個參數, g_model_len : 是型態為整數(int), 內容是模型參數的個數, 在這個模型裡面, 有 2,488 個參數 g_model[] : 是型態為’字元’(char)的’串列’ (list), 內容就是模型的全部參數 (parameters); 每一個參數佔用一個 byte, 也就是 8 個 bits. bit(s) 跟 byte(s) 是電腦處理器及記憶體的基本單位, 其中 1 byte = 8 bits. 在電腦常用的名詞裡, byte 還是比 bit 常用, 不過, 為了避免混淆, 常用的表達方式是用 ‘B’ 來表示 byte, 用 ‘b’ 來表示 bit. 例如現今電腦的操作系統已經進化到 64 位元(bits), 意思是 CPU 一次就可以處理 64 位元的資料, 而記憶體比較常用 128GB (bytes) 方式表達. 如第一個的內容 0x1c, 0x 指的是以 16 進位(相對於人類使用的 10進位) 的方式表達, 在 16 進位的表達方式, 我們用英文字元 a - f 來表達 10 - 15 的數字. 10 進位 16 進位 0x開頭 8 進位 0o開頭 0 0x0 0o0 1 0x1 0o1 2 0x2 0o2 3 0x3 0o3 4 0x4 0o4 5 0x5 0o5 6 0x6 0o6 7 0x7 0o7 8 0x8 0o10 9 0x9 0o11 10 0xa 0o12 11 0xb 0o13 12 0xc 0o14 13 0xd 0o15 14 0xe 0o16 15 0xf 0o17 16 0x10 0o20 17 0x11 0o21 18 0x12 0o22 19 0x13 0o23 20 0x14 0o24 21 0x15 0o25 22 0x16 0o26 23 0x17 0o27 24 0x18 0o30 25 0x19 0o31 26 0x1a 0o32 27 0x1b 0o33 28 0x1c 0o34 29 0x1d 0o35 30 0x1e 0o36 31 0x1f 0o37 32 0x20 0o40 也就是說, 這個模型會佔用開發板上面記憶體(ROM)的 2,488 位元組(bytes), g_model_len 說明這個模型的參數個數, 模型的參數內容則儲存在 g_model[]. # Print the C source file !cat {MODEL_TFLITE_MICRO} unsigned char g_model[] = { 0x1c, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x14, 0x00, 0x20, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x98, 0x00, 0x00, 0x00, 0xc8, 0x00, 0x00, 0x00, 0x1c, 0x03, 0x00, 0x00, ... 0x0c, 0x00, 0x10, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09 }; unsigned int g_model_len = 2488; "],["chap-hello-world-inference.html", "Chapter 5 Hello_world 範例程式 - 推論 5.1 在 STM32 DISCO_F746NG 上實現 hello_world 5.2 在 Arduino Nano 33 BLE 上實現 hello_world 5.3 在 ESP32-CAM 上實現 hello_world", " Chapter 5 Hello_world 範例程式 - 推論 本章節對應到 TinyML TensorFLow Lite 機器學習中文版 的第六章. (原書第五章是說明 hello_world 原始程式及測試碼, 可以當作後續的研究分析, 列入 §附錄 B 的主題) 上一章, 我們已經建立了可以轉移到開發板上執行的模型, 模型只是機器學習應用 app 的一部分而已, TFLM 提供不同開發板的 hello_world app, 需要在筆電上將模型加入原始程式, 重新編譯成不同開發板可以執行的程式碼(不同 CPU 的程式碼無法跨平台執行), 也可以在 PC 或 Mac 上模擬結果. 本文介紹可以運作 hello_world 示範程式的有以下的前兩種 (網路上有更新, 可以支援更多設備): Arduino Nano 33 BLE Sense ST Microelectronics STM32F746NG Discovery kit SparkFun Edge (TinyML TensorFLow Lite 機器學習中文版 書上有介紹, 但手上沒有這塊開發板, 就不介紹了) 2021/4/6 新增實驗 ESP32-CAM 5.1 在 STM32 DISCO_F746NG 上實現 hello_world 5.1.1 (無痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG 因為 TensorFlow Lite Micro 的開發持續在進行, 部份文件並沒有隨著開發進度而更新, 如果照著 github 上執行會產生一些錯誤, 而且, 在編譯 (make) 之前, 需要將 STM32 DISCO_F746NG 相關檔案複製到主程式目錄下, 因此, 我在 github 創建了一個 branch, 針對 DISCO_F746NG 的開發板做了檔案安排及設定調整, 可以直接編譯, 並下載到 DISCO_F746NG 開發板上執行. 參考我的 TFLM github - hello_world無痛執行 在下一節說明如果從 TFLM github 官網下載內容時, 需要做的修改. 5.1.2 (微痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG 此節乃針對已經熟悉上一節的內容, 順利執行後, 進一步從 TFLM github 官網下載, 得自行修改部份內容方能順利執行無誤. 動手修改內容 需要修改的內容有 1. 改從 https://github.com/tensorflow 官網下載 2. 將 tensorflow/lite/micro/examples/hello_world/disco_f746ng/ 這目錄改名成為 tensorflow/lite/micro/examples/hello_world/mbed/ 其餘從 make 以後的操作維持跟原先內容不變 5.1.2.1 改從 https://github.com/tensorflow 官網下載 # 從我的 github $ git clone -b example --depth 1 https://github.com/marconi1964/tensorflow.git # 改到用 Tensorflow 官網的 github $ git clone --depth 1 https://github.com/marconi1964/tensorflow.git # 或是 $ git clone --depth 1 https://github.com/tensorflow/tensorflow.git $ cd tensorflow 5.1.2.2 將 tensorflow/lite/micro/examples/hello_world/disco_f746ng/ 這目錄改名成為 tensorflow/lite/micro/examples/hello_world/mbed/ DISCO_F746NG 的驅動程式 (constant.cc 與 output_handler.cc) 跟標準的示範程式不同, 需要讓 make 把 F746NG 的驅動程式包含在主程式才能在開發板上執行, 這部分已經在 Makefile 完成, 只是目前 Makefile 的寫法是擷取 TARGET=mbed 中的 ‘mbed,’ 再到 hello_world 目錄下尋找 ‘mbed’ 子目錄 (這部分的程式設定有問題, 已經在 TensorFlow github 上發 issue), 而 mbed 子目錄是不存在, 且 Makefile 不會去尋找 disco_f746ng 子目錄. # 接續上一個動作, 已經在 tensorflow 目錄下, 切換到 hello_world 示範程式目錄 $ cd tensorflow/lite/micro/examples/hello_world/ $ mv disco_f746ng mbed # 完成後, 回到 tensorflow 主目錄下 $ cd ~/tensorflow (以上的動作, 看起來很簡單, 卻是我花最多時間的地方, 需要去了解 Makefile 及層層疊加上的 Makefile.inc 和 *_makefile.inc 的複雜架構.) 繼續執行 make 以及後續的動作 $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed ALL_TAGS=disco_f746ng generate_hello_world_mbed_project $ cd tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4_default/prj/hello_world/mbed $ mbed config root . $ mbed deploy $ mbed compile -m DISCO_F746NG -t GCC_ARM 5.1.2.3 將 make 後的 mbed.bin 上傳到 DISCO_F746NG 開發板 5.1.3 (痛苦的 debug過程) DISCO_F746NG 執行 hello_world 當機 第一次執行時, 還來不及沒有打開 screen 接收 debug 訊息, 就一顆球在上方定住, 懷疑我的操作/操守有問題… 打開 screen, 出現 ** Error message ** x_value: 1.0*2^-127, y_value: 1.0*2^-127 x_value: 1.4361557*2^-4, y_value: 1.7621826*2^-4 x_value: 1.4361557*2^-3, y_value: 1.8977352*2^-3 x_value: 1.0771168*2^-2, y_value: 1.389413*2^-2 x_value: 1.4361557*2^-2, y_value: 1.5588537*2^-2 x_value: 1.7951952*2^-2, y_value: 1.7960706*2^-2 x_value: 1.0771168*2^-1, y_value: 1.965511*2^-2 x_value: 1.2566366*2^-1, y_value: 1.1183078*2^-1 x_value: 1.4361557*2^-1, y_value: 1.3724688*2^-1 x_value: 1.6156756*2^-1, y_value: 1.4910772*2^-1 x_value: 1.7951952*2^-1, y_value: 1.6605182*2^-1 x_value: 1.9747147*2^-1, y_value: 1.7791265*2^-1 x_value: 1.0771168*2^0, y_value: 1.7791265*2^-1 x_value: 1.1668766*2^0, y_value: 1.8977352*2^-1 x_value: 1.2566366*2^0, y_value: 1.9316229*2^-1 x_value: 1.3463962*2^0, y_value: 1.965511*2^-1 x_value: 1.4361557*2^0, y_value: 1.0166438*2^0 ++ MbedOS Fault Handler ++ FaultType: HardFault Context: R0: 7C R1: 8 R2: FFDB4437 R3: 1 R4: 20002D58 R5: 34 R6: A R7: FFDB4437 R8: 0 R9: 72 R10: 8 R11: 68 R12: 34 SP : 2004FF8C LR : 800051B PC : 8000472 xPSR : 1000200 PSP : 0 MSP : 2004FF20 CPUID: 410FC271 HFSR : 40000000 MMFSR: 0 BFSR : 4 UFSR : 0 DFSR : 9 AFSR : 0 Mode : Thread Priv : Privileged Stack: MSP -- MbedOS Fault Handler -- ++ MbedOS Error Info ++ Error Status: 0x80FF013D Code: 317 Module: 255 Error Message: Fault exception Location: 0x8000472 Error Value: 0x20002E34 For more info, visit: https://mbed.com/s/error?error=0x80FF013D&amp;tgt=DISCO_F746NG -- MbedOS Error Info -- 查看 https://mbed.com/s/error?error=0x80FF013D&amp;tgt=DISCO_F746NG 輸入錯誤碼 (error code) 0x80FF013D 後會產生以下訊息 Error Decoder 0x80FF013D Type: System Module Unknown module Error Code HardFault exception Cortex-M HardFault exception has occurred. Please see https://os.mbed.com/docs/latest/tutorials/analyzing-mbed-os-crash-dump.html for more info. 進一步查看 https://os.mbed.com/docs/latest/tutorials/analyzing-mbed-os-crash-dump.html The following Cortex-M fault exceptions trigger the Mbed OS fault exception handler. MemManage Exception - Memory accesses that violate the setup in the MPU and certain illegal memory accesses trigger memory management faults. BusFault Exception - When an error response is received during a transfer on the AHB interfaces, it produces bus faults. UsageFault Exception - Division by zero, unaligned accesses and trying to execute coprocessor instructions can cause usage faults. HardFault Exception - Triggered on all fault conditions or if the corresponding fault handler (one of the above) is not enabled. 猜可能是記憶體問題, 再看一下螢幕當機時, 球是在螢幕的最上方, 是否是超過螢幕的範圍而造成錯誤, 看一下原始檔案 output_handler.cc 跟 error message 可能是有衝突的. # error message x_value: 1.4361557*2^0, y_value: 1.0166438*2^0 # output_handler.cc y_pos = dot_radius + static_cast&lt;int&gt;(midpoint * (1.f - y_value)); # 原始程式會有問題 y_pos = dot_radius + static_cast&lt;int&gt;(midpoint * (1.1f - y_value)); # 小調整後即可正常運作 5.2 在 Arduino Nano 33 BLE 上實現 hello_world 在 §3.4 Arduino IDE 安裝後, 將 Arduino Nano 33 BLE 接上電腦的 USB, 進入 Arduino IDE 的 Tools - Boards 及 Port 確定已經安裝完成, 再到 File - Examples 找到 Arduino_TensorFlowLite 下會有 4 個範例 hello_world magic_wand micro_speech person_detection 選擇我們想要的範例 hello_world 執行即可. 執行中, 可以打開 Arduino IDE menu * Tool - Serial Monitor : 看到 Nano 33 回饋的預測 X、Y 值 * Tool - Serial Plotter : 看到 Nano 33 回饋的預測 X、Y 值展開的圖形 同時, Nano 33 的燈號也會隨著辨識結果, 逐漸變亮到熄滅再變亮 5.3 在 ESP32-CAM 上實現 hello_world 這裡不說明 Arduino 的作法(作法更 Arduino Nano 33 大同小異), 僅就 esp-idf 方法做說明 在 §3.6 esp-idf 安裝且測試完 ESP32 的 hello world 後, 現在測試的是 TensorFlow Lite Micro 的 hello_world. 類似 STM32 DISCO_F746NG 的 Makefile 的作法 在 idf.py build 這步驟出現錯誤 $ git clone https://github.com/tensorflow/tensorflow.git $ cd tensorflow $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project $ cd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf $ idf.py build -- Configuring done CMake Error at /home/rafael/esp/esp-idf/tools/cmake/project.cmake:461 (target_link_libraries): Error evaluating generator expression: $&lt;IN_LIST:-DTF_LITE_STATIC_MEMORY,$&lt;TARGET_PROPERTY:__idf_tfmicro,COMPILE_OPTIONS&gt;&gt; Expression did not evaluate to a known generator expression Call Stack (most recent call first): CMakeLists.txt:3 (project) CMake Error in main/CMakeLists.txt: Error evaluating generator expression: $&lt;IN_LIST:-DTF_LITE_STATIC_MEMORY,$&lt;TARGET_PROPERTY:__idf_tfmicro,COMPILE_OPTIONS&gt;&gt; Expression did not evaluate to a known generator expression -- Generating done -- Build files have been written to: /home/rafael/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf/build cmake failed with exit code 1 Google 後發現 ESP32 Hello World project crashing in the target 說明 cmake 的 compile option 需要 3.11 版本以上, 查了我的 cmake 版本是 3.10.2, 所以需要升級 $ cmake --version cmake version 3.10.2 cmake 升級作法 # 從 https://cmake.org/download/ 下載 tar file, 到下載 tar file 的目錄下執行: $ cd $CMAKE_DOWNLOAD_PATH $ ./configure $ make $ sudo make install 再執行 idf, 可以結束從開發板傳回來的 X 跟 Y 的值 $ idf.py build $ idf.py -p PORT flash monitor 提醒 : 執行 monitor 程式時, 如果要離開, 需要按 ‘Ctrl’ + ‘]’ 的組合鍵. "],["chap-micro-speech-inference.html", "Chapter 6 Micro_speech 範例程式-喚醒詞偵測：建構 app 6.1 在 STM32 DISCO_F746NG 上實現 micro_speech 6.2 在 Arduino Nano 33 BLE 上實現 micro_speech", " Chapter 6 Micro_speech 範例程式-喚醒詞偵測：建構 app 本章節對應到 TinyML TensorFLow Lite 機器學習中文版 的第七章, 佩服作者在機器學習功力的深厚, 在這一章裡, 也介紹了機器學習 app 的模型框架, 以及語音樣本資料 - 聲譜 (spectrogram) - 的簡介. 我會再後續補充於 Appendix §C 音頻聲譜的說明與模型分析. 再說一次: 訓練就是‘學習’; 推論就是‘考試’ 這個範例, 作者先從 inference - 喚醒詞偵測的構建 app 開始, 訓練模型留待下一章 (第 §7 章) 介紹. 本文介紹可以運作 micro_speech 示範程式的有以下的前兩種 (網路上有更新, 可以支援更多設備): Arduino Nano 33 BLE Sense ST Microelectronics STM32F746NG Discovery kit SparkFun Edge (TinyML TensorFLow Lite 機器學習中文版 書上有介紹, 但手上沒有這塊開發板, 就不介紹了) 6.1 在 STM32 DISCO_F746NG 上實現 micro_speech 6.1.1 (無痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG 因為 TensorFlow Lite Micro 的開發持續在進行, 部份文件並沒有隨著開發進度而更新, 如果照著 github 上執行會產生一些錯誤, 而且, 在編譯 (make) 之前, 需要將 STM32 DISCO_F746NG 相關檔案複製到主程式目錄下, 因此, 我在 github 創建了一個 branch, 針對 DISCO_F746NG 的開發板做了檔案安排及設定調整, 可以直接編譯, 並下載到 DISCO_F746NG 開發板上執行. 參考我的 TFLM github - micro_speech無痛執行 在下一節說明如果從 TFLM github 官網下載內容時, 需要做的修改. 6.1.2 (微痛執行)在筆電上編譯程式, 並下載至 STM32 DISCO_F746NG 此節乃針對已經熟悉上一節的內容, 順利執行後, 進一步從 TFLM github 官網下載, 得自行修改部份內容方能順利執行無誤. 動手修改內容 需要修改的內容有 1. 改從 https://github.com/tensorflow 官網下載 2. 將 tensorflow/lite/micro/examples/micro_speech/disco_f746ng/ 這目錄改名成為 tensorflow/lite/micro/examples/micro_speech/mbed/ 其餘從 make 以後的操作維持跟原先內容不變 6.1.2.1 改從 https://github.com/tensorflow 官網下載 # 從我的 github $ git clone -b example --depth 1 https://github.com/marconi1964/tensorflow.git # 改到用 Tensorflow 官網的 github $ git clone --depth 1 https://github.com/marconi1964/tensorflow.git # 或是 $ git clone --depth 1 https://github.com/tensorflow/tensorflow.git $ cd tensorflow 6.1.2.2 將 tensorflow/lite/micro/examples/micro_speech/disco_f746ng/ 這目錄改名成為 tensorflow/lite/micro/examples/micro_speech/mbed/ DISCO_F746NG 的驅動程式 (audio_provider.cc 與 command_responder.cc) 跟標準的示範程式不同, 需要讓 make 把 F746NG 的驅動程式包含在主程式才能在開發板上執行, 這部分已經在 Makefile 完成, 只是目前 Makefile 的寫法是擷取 TARGET=mbed 中的 ‘mbed,’ 再到 micro_speech 目錄下尋找 ‘mbed’ 子目錄, 而不是尋找 disco_f746ng 子目錄, 且 mbed 子目錄是不存在的, 這是問題所在, 因此需要做以下調整. # 接續上一個動作, 已經在 tensorflow 目錄下, 切換到 micro_speech 示範程式目錄 $ cd tensorflow/lite/micro/examples/micro_speech/ $ mv disco_f746ng mbed # 完成後, 回到 tensorflow 主目錄下 $ cd ~/tensorflow (以上的動作, 看起來很簡單, 卻是我花最多時間的地方, 需要去了解 Makefile 及層層疊加上的 Makefile.inc 和 *_makefile.inc 的複雜架構.) 繼續執行 make 以及後續的動作 $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed ALL_TAGS=disco_f746ng generate_micro_speech_mbed_project $ cd tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4_default/prj/micro_speech/mbed $ mbed config root . $ mbed deploy $ mbed compile -m DISCO_F746NG -t GCC_ARM 執行後, 可以打開 screen 或 Coolterminal 來監看 DISCO_F746NG 偵測 ‘yes,’ ‘no,’ ‘unknown,’ 或 ‘silence’ 的預測結果各是如何. 此處的模型很小, 也不完美, 你會發現它比較擅長偵測 ‘yes,’ 處理 ‘no’ 的效果較差, 從這個例子可以看到小型模型的大小進行優化將導致準確性下降, 將在下一個章節 (第 §7 章) 進一步討論這主題 6.2 在 Arduino Nano 33 BLE 上實現 micro_speech 在 §3.4 Arduino IDE 安裝後, 將 Arduino Nano 33 BLE 接上電腦的 USB, 進入 Arduino IDE 的 Tools - Boards 及 Port 確定已經安裝完成, 再到 File - Examples 找到 Arduino_TensorFlowLite 下會有 4 個範例 hello_world magic_wand micro_speech person_detection 選擇我們想要的範例 micro_speech. 打開後, IDE 環境會同時展開好幾個程式, 找到 model.cpp 檔案, 用 colab 訓練完成的 g_model[ ] 內容來取代現有 model.cpp 內的 g_model[ ], 即可按照一般 Arduino 的程式般下載到 Nano 33 BLE 後執行. 執行中, 可以打開 Arduino IDE menu * Tool - Serial Monitor : 看到 Nano 33 回饋的預測是 ‘yes,’ ‘no,’ ‘unknown,’ 或 ‘silence’ 同時, Nano 33 的燈號顏色也會隨著辨識結果也不同 yes: 綠燈 no: 紅燈 unknown: 藍燈 silence: (不亮燈) 此處的模型很小, 也不完美, 你會發現它比較擅長偵測 ‘yes,’ 處理 ‘no’ 的效果較差, 從這個例子可以看到小型模型的大小進行優化將導致準確性下降, 將在下一個章節 (第 §7 章) 進一步討論這主題 "],["chap-micro-speech-training.html", "Chapter 7 Micro_speech 範例程式-喚醒詞偵測：訓練模型 7.1 在 Google colab 上建立及訓練 micro_speech 的模型 (原始程式及設定) 7.2 在 Google colab 上建立及訓練客製化 micro_speech 的模型", " Chapter 7 Micro_speech 範例程式-喚醒詞偵測：訓練模型 本章節對應到 TinyML TensorFLow Lite 機器學習中文版 的第八章, 在這一章裡, 也介紹了 TensorBoard 來監看訓練過程, 可以進一步了解可視化機器學習. 本章最後一小部分, 也再說明語音特徵生產的程序, 這部分, 我有機會再於 Appendix §C 音頻聲譜的說明與模型分析說明. 類似 hello_world 的範例程式的模型訓練是於 Google colab 上執行, 此 micro_speech 範例也是在 colab 上執行另一個模型訓練程式, 我們先不做任何的修改, 於下一段的 colab 訓練客製化可以修改原始辨識 ‘yes’ 與 ‘no’ 的模型, 改為辨識其它喚醒詞. 7.1 在 Google colab 上建立及訓練 micro_speech 的模型 (原始程式及設定) 到 github 的 Train a Simple TensorFlow Lite for Microcontrollers model 會同時看到 “在 Google colab 上執行” 及 “github 原始碼” 的圖示如下, 我們點選 “在 Google colab 上執行,” 就會在 browser 上新開一個畫面, 執行 colab 上的 training 程式. 7.1.1 colab 執行 training 程式前的準備工作 機器學習需要大量的運算, 尤其是浮點運算, 所以 NVidia 的 GPU 比 intel 的 CPU 更適合做機器學習的訓練工作, 可以縮短大量的訓練時間. Google 的 colab 提供了 3 種 runtime type 的選擇, 到選單 ‘Runtime’ 下的 “Change runtime type” 選擇 GPU. (如果選擇 None, 就會使用 CPU, 選擇 TPU, 會使用 Google 特殊設計的機器學習加速晶片, 截至目前為止, GPU 還是機器學習訓練速度最快的選項. 只是, 本次訓練的模型不大, 不管選擇哪一種, 時間都差異不大) 7.1.2 colab 執行 train micro_speech model.ipynb 程式 到選單 “Runtime” 選擇 “Run all,” 整個執行過程所需時間比 hello_world 的訓練長出許多, 我曾經有跑過 4 個小時以上 (可能是我同時在 colab 有跑其它應用有關, 同學們可以試試看不同的 runtime type 所需的時間各是多少), 原始程式也提供一個縮短訓練時間的方式, 把下面最底下 2 行的指令 # 拿掉 (!curl 跟 !tar 開頭那 2 行) , 直接下載已經訓練好的模型, 我在這樣條件下執行的時間約為 3.5 個小時. Skipping the training If you don&#39;t want to spend an hour or two training the model from scratch, you can download pretrained checkpoints by uncommenting the lines below (removing the &#39;#&#39;s at the start of each line) and running them. #!curl -O &quot;https://storage.googleapis.com/download.tensorflow.org/models/tflite/speech_micro_train_2020_05_10.tgz&quot; #!tar xzf speech_micro_train_2020_05_10.tgz 7.1.3 將模型上傳至開發板 類似 hello_world 的作法, 將 colab 訓練結果複製貼上到開發板的 app, 我們回到開發環境, 需要注意 3 個地方 更換模型 - 複製貼上到 model.cc 確認 micro_model_settings.cc 確認 command_responder.cc 7.1.3.1 更換模型 - 將 colab 訓練結果的 g_model[ ] 內容複製貼上到 model.cc colab 訓練最後一行的 g_model[ ] 的內容 (書上寫的 g_tiny_conv_micro_features_model_data[ ] 資料太舊, 已經更新為 g_model[ ]), 複製貼上到 , tensorflow/lite/micro/examples/micro_speech/micro_features/model.cc 內容的 g_model[ ]. 並確認 g_model_len = 18712 的數字部份與 colab 的 g_model_len 一致, 如有不同, 採用 colab 的數字. !cat {MODEL_TFLITE_MICRO} const unsigned char g_model[] DATA_ALIGN_ATTRIBUTE = { 0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x12, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x94, 0x48, 0x00, 0x00, 0x34, 0x42, 0x00, 0x00, 0x1c, 0x42, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, ...... 0x06, 0x00, 0x00, 0x00, 0x00, 0x16, 0x0a, 0x00, 0x0e, 0x00, 0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x0c, 0x00, 0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x03, 0x00, 0x00, 0x00}; const int g_model_len = 18712; 7.1.3.2 確認 micro_model_settings.cc 打開 examples/micro_speech/micro_features/micro_model_settings.cc, 這個檔案有關類別標籤陣列, 確定跟 colab 裡面的是一致的. const char* kCategoryLabels[kCategoryCount] = { &quot;silence&quot;, &quot;unknown&quot;, &quot;yes&quot;, &quot;no&quot;, }; 7.1.3.3 確認 command-responder.cc - 以 DISCO_F746NG 為例 DISCO_F746NG 指令回應器檔案位於 examples/micro_speech/disco_f746ng/command_responder.cc, 它會根據聽到的指令來顯示不同的單字, 在檔案裡面可以找到這個 if 陳述式: if (*found_command == &#39;y&#39;) { lcd.Clear(0xFF0F9D58); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard yes!&quot;, CENTER_MODE); } else if (*found_command == &#39;n&#39;) { lcd.Clear(0xFFDB4437); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard no&quot;, CENTER_MODE); } else if (*found_command == &#39;u&#39;) { lcd.Clear(0xFFF4B400); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard unknown&quot;, CENTER_MODE); } else { lcd.Clear(0xFF4285F4); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard silence&quot;, CENTER_MODE); } 7.1.4 接續執行 make 及程式上傳 接下去再回頭執行上一章介紹的推論部份的動作 §6.1.2.2 修改 disco_f746ng 目錄繼續執行. 7.2 在 Google colab 上建立及訓練客製化 micro_speech 的模型 我們接下來進行的客製化的過程, 可以讓你選擇的開發板, 不僅是辨識此範例中的 ‘yes’ 與 ‘no,’ 而是有其它選擇, 甚至超過 2 個以上的單字當作喚醒詞辨識. 因為範例中的模型設計, 可以選取的單字有下列, 我們會選用 ‘on’ 與 ‘off’ 當作此次的範例. 常見指令: yes, no, up, down, left, right, on, off, stop, go backward, foward, follow, learn 0 - 9 數字: zero, one, two, three, four, five, six, seven, eight, nine 隨機單字: bed, bird, cat, dog, happy, house, Marvin, Sheila, tree, wow 需要修改的有 4 個部份, 1 個在 colab 訓練程式, 3 個在開發板開發環境的程式內容 修改 colab 訓練程式 更換模型 修改 micro_model_settings.cc 修改 command_responder.cc (️ 注意: 如果是選用其它開發板, 如 DISCO_F746NG 時, Makefile 會選用其它目錄下的 /micro_speech/disco_f746ng/command_responder.cc, 這時候需要修改的檔案就是 disco_f746ng 目錄下的) 7.2.1 修改 colab 訓練程式 到 Google colab 的 train_micro_speech_model.ipynb 下尋找 WANTED_WORDS, 可以看到下面這行 WANTED_WORDS = &quot;yes,no&quot; 我們接下來的練習用 ‘on,’ ‘off’ 來取代 WANTED_WORDS = &quot;on, off&quot; 到選單 “Runtime” 選擇 “Run all” 7.2.2 更換模型 - 將 colab 訓練結果的 g_model[ ] 內容複製貼上到 model.cc 等 colab 訓練完成後, 將最後一行的 g_model[ ] 的內容 (書上寫的 g_tiny_conv_micro_features_model_data[ ] 資料太舊, 已經更新為 g_model[ ]), 複製貼上到 , tensorflow/lite/micro/examples/micro_speech/micro_features/model.cc 內容的 g_model[ ]. 並確認 g_model_len = 18712 的數字部份與 colab 的 g_model_len 一致, 如有不同, 採用 colab 的數字. !cat {MODEL_TFLITE_MICRO} const unsigned char g_model[] DATA_ALIGN_ATTRIBUTE = { 0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x12, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x94, 0x48, 0x00, 0x00, 0x34, 0x42, 0x00, 0x00, 0x1c, 0x42, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, ...... 0x06, 0x00, 0x00, 0x00, 0x00, 0x16, 0x0a, 0x00, 0x0e, 0x00, 0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x0c, 0x00, 0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x03, 0x00, 0x00, 0x00}; const int g_model_len = 18712; 7.2.3 修改 micro_model_settings.cc 打開 tensorflow/lite/micro/examples/micro_speech/micro_features/micro_model_settings.cc, 這個檔案有關類別標籤陣列： const char* kCategoryLabels[kCategoryCount] = { &quot;silence&quot;, &quot;unknown&quot;, &quot;yes&quot;, &quot;no&quot;, }; 我們為新模型進行調整, 將 ‘yes’ 與 ‘no’ 換成 ‘on’ 與 ‘off,’ 我們讓標籤的順序與模型輸出張量 (tensor) 的元素順序一樣, 讓它們的順序與訓練腳本裡面的相同非常重要. (如果用來訓練模型的標籤超過 2 個, 只要將它們都加入這個串列即可) const char* kCategoryLabels[kCategoryCount] = { &quot;silence&quot;, &quot;unknown&quot;, &quot;on&quot;, &quot;off&quot;, }; 7.2.4 修改 command_responder.cc 最後一個步驟是修改使用這些標籤的輸出程式碼, 我們以 STM32 DISCO_F746NG 為例. STM32 DISCO_F746NG 指令回應器位於 examples/micro_speech/disco_f746ng/command_responder.cc, 它會根據聽到的指令來顯示不同的單字, 在 command_responder.cc 裡面找到以下這個 if 陳述式: if (*found_command == &#39;y&#39;) { lcd.Clear(0xFF0F9D58); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard yes!&quot;, CENTER_MODE); } else if (*found_command == &#39;n&#39;) { lcd.Clear(0xFFDB4437); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard no&quot;, CENTER_MODE); } else if (*found_command == &#39;u&#39;) { lcd.Clear(0xFFF4B400); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard unknown&quot;, CENTER_MODE); } else { lcd.Clear(0xFF4285F4); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard silence&quot;, CENTER_MODE); } 將它改成回應 ‘on’ 與 ‘off’ 不算太難, 只是之前只要判斷第一個字母的差異 (*found_command 來區分 yes 第一個字母的 ‘y’ 與 no 的 ‘n’), 現在必須用 2 個字母來區別 (found_command[0] 與 found_command[1] 來區分 on 的 ‘on’ 與 off 的 ‘of’) if (found_command[0] == &#39;o&#39; &amp;&amp; found_command[1] == &#39;n&#39;) { lcd.Clear(0xFF0F9D58); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard on!&quot;, CENTER_MODE); } else if (found_command[0] == &#39;o&#39; &amp;&amp; found_command[1] == &#39;f&#39;) { lcd.Clear(0xFFDB4437); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard off&quot;, CENTER_MODE); } else if (*found_command == &#39;u&#39;) { lcd.Clear(0xFFF4B400); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard unknown&quot;, CENTER_MODE); } else { lcd.Clear(0xFF4285F4); lcd.DisplayStringAt(0, LINE(5), (uint8_t*)&quot;Heard silence&quot;, CENTER_MODE); } 7.2.5 接續執行 make 及程式上傳 接下去再回頭執行上一章介紹的推論部份的動作 §6.1.2.2 修改 disco_f746ng 目錄繼續執行. "],["chap-magic-wand.html", "Chapter 8 Magic_wand 範例程式", " Chapter 8 Magic_wand 範例程式 "],["chap-person-detection.html", "Chapter 9 Person_detection 範例程式", " Chapter 9 Person_detection 範例程式 在 §3.6 esp-idf 安裝 ESP32-CAM 開發環境後, 進一步測試人物辨識程式 person_detection $ git clone https://github.com/tensorflow/tensorflow.git $ cd tensorflow $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project 出現 github 已經在討論的 ESP32-CAM person_detectin problem, 我試過後, 加入我的可行作法 $ git clone --depth 1 https://github.com/tensorflow/tensorflow.git $ cd tensorflow/ $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project # error occurs, same as yours, I believe. # 下載 https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/47063.patch # 或是 git cherry-pick 6d69beaf73fa2488f830a7fb7ed4ef931b44ce1d $ ls 47063.patch # to make sure patch is downloaded $ git apply ./47063.patch $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project # it generate another error below and stop. make: *** No rule to make target &#39;tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf/main/person_model_int8/person_detect_model_data.cc&#39;, needed by &#39;generate_person_detection_esp_project&#39;. Stop. $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_int8_project # this command generate another error of below, but it seems fix the previous error. make: *** No rule to make target &#39;generate_person_detection_esp_int8_project&#39;. Stop. $ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project # so we re-do the generate_person_detection_esp_project again, it works and no error. 接下來, 執行 esp-idf 指令 $ cd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/person_detection/esp-idf $ idf.py build $ idf.py -p PORT flash monitor 這時候, ESP32-CAM 的執行結果傳回電腦的以下的錯誤訊息 rst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT) configsip: 0, SPIWP:0xee clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00 mode:DIO, clock div:1 load:0x3fff0018,len:4 load:0x3fff001c,len:1216 ho 0 tail 12 room 4 load:0x40078000,len:9720 ho 0 tail 12 room 4 load:0x40080400,len:6352 entry 0x400806b8 [E][camera.c:1049] camera_probe(): Detected camera not supported. [E][camera.c:1249] esp_camera_init(): Camera probe failed with error 0x20004 Camera init failed InitCamera failed Image capture failed 找到 esp-32 Camera probe failed with error 0x20004 文章提到 2 個可能 ESP32-CAM 從 3.3V 改成 5V 將程式原始設定的預設的開發板 WROVER-KIT With OV2640 Module 改成 CAMERA_MODEL_AI_THINKER, 修改的檔案是 esp-idf examples/person_detection/esp/app_camera_esp.h 似乎是需要在 menuconfig 中做設定, 將 CONFIG_CAMERA_MODEL_AI_THINKER 設成 TRUE ``` #if CONFIG_CAMERA_MODEL_WROVER_KIT #define PWDN_GPIO_NUM -1 #define RESET_GPIO_NUM -1 …. #elif CONFIG_CAMERA_MODEL_AI_THINKER #define PWDN_GPIO_NUM 32 #define RESET_GPIO_NUM -1 ``` * examples/person_detection/esp/main/Kconfig.projbuild * 修改第 17 行 ``` default CAMERA_MODEL_WROVER_KIT # line 17 # 改成 default ESP32-CAM by AI-Thinker ``` Arduino: 如果是在 Arduino 上的應用 (不一定是 person_detection), 需要修改的設定如下: // Select camera model //#define CAMERA_MODEL_WROVER_KIT //#define CAMERA_MODEL_ESP_EYE //#define CAMERA_MODEL_M5STACK_PSRAM //#define CAMERA_MODEL_M5STACK_WIDE #define CAMERA_MODEL_AI_THINKER "],["references-.html", "References 參考文獻", " References 參考文獻 本書是基於 TinyML TensorFLow Lite 機器學習中文版 內容的實驗結果, 作者 Pete Warden 及 Daniel Situnayake 均於 Google 工作. 可以參考 Pete 相關論文、影片如下. 關於 Make 及 Makefile 1. 取消 TAGS 程式不受影響 2. STM32F 選用 OPTIMIZED_KERNEL_DIR=cmsis_nn 來做最佳化 英文參考文章 mbed / arm / STM 3. mbed-cli v6.7 installation 4. mbed-cli v5.15 manual installation 5. Build Arm Cortex-M voice assistant with Google TensorFlow Lite 6. CMSIS - Cortex Microcontroller Software Interface Standard 7. STM32F10x Standard Peripherals Library Peripheral’s Drivers Description 8. what means about “-DSTM32F10X_MD -DUSE_STDPERIPH_DRIVER” as the flags of arm-none-eabi-gcc? Arduino 相關 9. USB 無法偵測到 Arduino Nano BLE 33 : 我一開始從 Mac 下載程式到 Nano 後, Nano 執行結果不如預期, 擔心是 Mac 的 USB 有問題(一直有遇到類似問題), 轉到 PC Windows 下, 發現 USB 偵測不到 Nano, 甚至懷疑到我 PC 的 USB driver 有問題, 結果是, 如果 Nano 下載的程式有問題, 是有可能造成 USB 偵測不到, 需要 reset Nano, 重新刷 firmware, 後 USB 才能正常偵測到 Nano. 其它 10. Neural Network on Mobile (nnom) by Ma Jianjia - github TensorFlow 11. Tensorflow.org 官網 12. TensorFlow for microcontroller - 官網 13. Tensorflow Lite Micro on ESP32 14. TensorFlow for Micro Github 官網 open source 15. TensorFlow Lite for Microcontroller Hello world examples TinyML (TensorFlow Lite Micro 一開始使用的名稱) 16. 書 \"TinyML Tensor Flow Lite 機器學習“ 英文版 O’Reilly 出版 17. 書 \"TinyML Tensor Flow Lite 機器學習“ 中文版 O’Reilly 出版 18. pdf - TinyML_Machine_Learning_with_TensorFlow_Lite_on_Arduino_and_Ultra.pdf 19. ARM - build voice assistant on Cortex-M with TFLM 20. TinyML summit organization 21. TinyML summit 2021 22. Tiny summit 2021 Youtube playback - partial only 23. Meet up - 舊金山灣區 24. Meet up - 德州奧斯汀 25. SIG Micro - TensorFlow Embedded Group 26. SIG Micro mailing list 27. SIG Micro Gitter chat channel 28. SIG Micro monthly meeting notes and agenda 其它框架 29. uTensor - by ARM Neil Tan 30. Microsoft - Embedded Learning Library (ELL) : 主要針對 Arduino 與 micro:bit 平台 Pete Warden 及相關資料 31. Pete Warden’s blog 32. Paper - TensorFlow Lite Micro 33. Pete youtube TinyML book #1 chap 4 - hello world training model 34. Pete youtube TinyML book #2 chap 5/6 - Deploying the Hello World model on an Arduino 35. Pete youtube TinyML book #3 - Introduction to TensorFlow Lite for Microcontrollers 36. Pete youtube TinyML book #4 - Quantization 37. Pete youtube What’s TinyML good for @ AIoT Dev Summit keynote 38. Getting Started with TinyML - Pete Warden - TinyML.org - March 31, 2020 39. Getting Started with TinyML - Pete Warden - TinyML.org - March 31, 2020 - youtube 40. Getting Started with TinyML - Pete Warden - TinyML.org - March 31, 2020 - slides 41. Pete Warden, Staff Research Engineer and TensorFlow Lite development lead at Google, presents the “Using TensorFlow Lite to Deploy Deep Learning on Cortex-M Microcontrollers” tutorial at the May 2019 Embedded Vision Summit 42. Introducing the SparkFun Edge - Tiny models on tiny computers! 關於 TinyML 的另一位作者, 已經離開 Google 的 Daniel Situnayake 43. Daniel Situnayake’s blog 44. Edge Impluse 一個厲害德國人的 stupid projects, 在不同的 embedded controller 做 TFLM 的 benchmark 45. Stupid projects - Machine Learning on Embedded (Part 1) 46. Tensorflow 2.1.0 for microcontrollers benchmarks on STM32F746 "],["appendixa.html", "A Appendix A - 機器學習模型之加強及改善可能", " A Appendix A - 機器學習模型之加強及改善可能 "],["appendixb.html", "B Appendix B - Hello_world 原始碼分析", " B Appendix B - Hello_world 原始碼分析 "],["appendixc.html", "C Appendix C - 音頻聲譜的說明與模型分析", " C Appendix C - 音頻聲譜的說明與模型分析 "]]
